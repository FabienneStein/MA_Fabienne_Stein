{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a5b73-b581-477c-985e-6bdc297a4ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataImport.ipynb\n",
    "%run Plots.ipynb\n",
    "%run HelperFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d3796-32b6-44a9-9048-ea65902ba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merge_data()\n",
    "screw = data[0]\n",
    "tile = data[1]\n",
    "capsule = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c60080-e751-427c-9a79-49820d36e18b",
   "metadata": {},
   "source": [
    "# MVTEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268fe8c-16d8-4a4e-80a7-3a539605b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_append_to_txt_file(file_path, time):\n",
    "    '''\n",
    "    function to append time for the autogluon\n",
    "    '''\n",
    "    try:\n",
    "        with open(file_path, \"a\") as file:\n",
    "            file.write(str(time)+\"\\n\")\n",
    "    except FileNotFoundError:\n",
    "        with open(file_path, \"w\") as file:\n",
    "            file.write(str(time)+\"\\n\")\n",
    "\n",
    "def create_or_append_to_csv_file(file_path, data, count_all):\n",
    "    '''\n",
    "    function to append metrics to a csv file\n",
    "    '''\n",
    "    try:\n",
    "        # try to load the file\n",
    "        df = pd.read_csv(file_path)\n",
    "        # save the metrics\n",
    "        df.loc[len(df)] = data\n",
    "        df.to_csv(file_path, index=False)\n",
    "    except:\n",
    "        \n",
    "        # if file does not exists, make file\n",
    "        df_metrics_keras = pd.DataFrame(columns=[\"Accuracy\", \"ROC AUC\", \"Precision\", \"F1-score\", \"Time\"])\n",
    "        df_metrics_keras.loc[len(df_metrics_keras)] = data\n",
    "        df_metrics_keras.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def2275-735e-43e9-86f4-a66eabdea5ea",
   "metadata": {},
   "source": [
    "# AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a8702-787c-48ae-9e58-81328a181956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def classify(data, directory_name, time_name, metric_name):\n",
    "    seeds = [1,2,3,4,5,6,7,8,9,10]\n",
    "    time_autogluon = []\n",
    "    count_all = 0\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for j in seeds:\n",
    "        # load dataset\n",
    "        train_keras, test_keras = prepare_data(data,j)\n",
    "        X_test_keras, Y_test_keras = to_array(test_keras)\n",
    "        X_train_keras, Y_train_keras = to_array(train_keras)\n",
    "    \n",
    "        print(X_test_keras.shape)\n",
    "        print(Y_test_keras.shape)\n",
    "        print(X_train_keras.shape)\n",
    "        print(X_train_keras.shape)\n",
    "        \n",
    "        #directory_name = str(0)\n",
    "        if not os.path.exists(directory_name):\n",
    "            os.makedirs(directory_name)\n",
    "        # set the classifier\n",
    "        clf = ak.ImageClassifier(overwrite=True, \n",
    "                                 seed = j,\n",
    "                                 project_name=\"plots_im/Keras/\" + directory_name + \"/\"+ str(j), \n",
    "                                 max_trials = 50,\n",
    "                                 metrics = ['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()] )\n",
    "               \n",
    "        from datetime import datetime as dt\n",
    "        start_time = dt.now()\n",
    "    \n",
    "        # fit the model\n",
    "        hist = clf.fit(X_train_keras, Y_train_keras, epochs = 50)\n",
    "        \n",
    "        end_time = dt.now()   \n",
    "        # save the building time to give autogluon the same amount of time\n",
    "        elapsed_seconds = (end_time - start_time).total_seconds()\n",
    "        time_autogluon.append(elapsed_seconds)\n",
    "        elapsed_min = divmod(elapsed_seconds, 60)\n",
    "        # print the elapsed time\n",
    "        time_passed = f\"{int(elapsed_min[0])}m{int(elapsed_min[1])}s\"\n",
    "        print(\"Total fitting time: \", f\"{int(elapsed_min[0])}m{int(elapsed_min[1])}s\")\n",
    "    \n",
    "        # print model summarys\n",
    "        print(clf.tuner.results_summary())\n",
    "        \n",
    "        eval = clf.evaluate(X_test_keras, Y_test_keras)\n",
    "        print(eval)\n",
    "    \n",
    "        if (eval[3] + eval[4]) !=0:\n",
    "            f1_score = 2 * (eval[3] * eval[4]) / (eval[3] + eval[4])\n",
    "        else:\n",
    "            f1_score = 1\n",
    "        # add to dataFrame\n",
    "        row_f = {\"Accuracy\": eval[1], 'ROC AUC': eval[2], 'Precision': eval[3], \"F1-score\":f1_score,\"Time\":time_passed}\n",
    "        # save the metrics\n",
    "        #df_metrics_keras.loc[count_all] = row_f\n",
    "    \n",
    "    \n",
    "        create_or_append_to_txt_file(time_name,elapsed_seconds)\n",
    "        create_or_append_to_csv_file(metric_name, row_f, count_all)\n",
    "        \n",
    "        # get confusion matrix\n",
    "        y_prediction_keras = clf.predict(X_test_keras, batch_size = 1) \n",
    "        print('The confusion matrix is: ') \n",
    "        print(str(confusion_matrix(Y_test_keras, y_prediction_keras)))\n",
    "        \n",
    "        cm = confusion_matrix(Y_test_keras, y_prediction_keras)\n",
    "        print(cm)\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap=\"Greens\", cbar=True,\n",
    "                xticklabels=['0', '1'], \n",
    "                yticklabels=['0', '1'])\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.ylabel('True label')\n",
    "        plt.savefig(\"plots_im/Keras/Keras\" + directory_name +  str(j))# + name)\n",
    "        plt.show()\n",
    "        \n",
    "        clf.tuner.results_summary()\n",
    "        model = clf.export_model()\n",
    "    \n",
    "        # Save the model summary to a text file\n",
    "        str_name = \"plots_im/Keras/\" + directory_name +\".txt\"\n",
    "        model_summary_str = \"\"\n",
    "        model.summary(print_fn=lambda x: print(x, end=\"\\n\", file=open(str_name, \"a\")))\n",
    "    \n",
    "       \n",
    "        count += 1\n",
    "        count_all += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c8bc2-69ed-4320-b37d-3ef038f208dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(screw,\"0\", \"MVTEC_screw.txt\", \"plots_im/Keras/Keras_metrics_screw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51fb05-32aa-404a-ae13-8bbb1bc4b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(tile,\"1\", \"MVTEC_tile.txt\", \"plots_im/Keras/Keras_metrics_tile.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0f8c7-3051-4398-b019-92ed17fde541",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(capsule,\"2\", \"MVTEC_capsule.txt\", \"plots_im/Keras/Keras_metrics_capsule.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
